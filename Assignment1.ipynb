{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 47us/step - loss: 1.4829 - accuracy: 0.6231 - val_loss: 0.7584 - val_accuracy: 0.8286\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.6049 - accuracy: 0.8464 - val_loss: 0.4550 - val_accuracy: 0.8852\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.4398 - accuracy: 0.8801 - val_loss: 0.3710 - val_accuracy: 0.9019\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.3767 - accuracy: 0.8952 - val_loss: 0.3322 - val_accuracy: 0.9082\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.3415 - accuracy: 0.9025 - val_loss: 0.3055 - val_accuracy: 0.9147\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.3175 - accuracy: 0.9085 - val_loss: 0.2880 - val_accuracy: 0.9182\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.2989 - accuracy: 0.9137 - val_loss: 0.2727 - val_accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2839 - accuracy: 0.9179 - val_loss: 0.2608 - val_accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2714 - accuracy: 0.9218 - val_loss: 0.2504 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.2602 - accuracy: 0.9252 - val_loss: 0.2430 - val_accuracy: 0.9308\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2501 - accuracy: 0.9286 - val_loss: 0.2341 - val_accuracy: 0.9334\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2409 - accuracy: 0.9301 - val_loss: 0.2271 - val_accuracy: 0.9352\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2325 - accuracy: 0.9334 - val_loss: 0.2227 - val_accuracy: 0.9367\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.2253 - accuracy: 0.9353 - val_loss: 0.2147 - val_accuracy: 0.9396\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2181 - accuracy: 0.9375 - val_loss: 0.2082 - val_accuracy: 0.9411\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2116 - accuracy: 0.9394 - val_loss: 0.2030 - val_accuracy: 0.9431\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.2055 - accuracy: 0.9413 - val_loss: 0.1981 - val_accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.1996 - accuracy: 0.9430 - val_loss: 0.1932 - val_accuracy: 0.9458\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.1941 - accuracy: 0.9432 - val_loss: 0.1894 - val_accuracy: 0.9467\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.1890 - accuracy: 0.9456 - val_loss: 0.1850 - val_accuracy: 0.9498\n",
      "10000/10000 [==============================] - 1s 77us/step\n",
      "Test score: 0.18599885640591382\n",
      "Test accuracy: 0.9463000297546387\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(1671) # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 1.3439 - accuracy: 0.6629 - val_loss: 0.6884 - val_accuracy: 0.8442\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.5708 - accuracy: 0.8568 - val_loss: 0.4410 - val_accuracy: 0.8870\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.4284 - accuracy: 0.8845 - val_loss: 0.3661 - val_accuracy: 0.9018\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.3712 - accuracy: 0.8973 - val_loss: 0.3311 - val_accuracy: 0.9076\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.3389 - accuracy: 0.9050 - val_loss: 0.3069 - val_accuracy: 0.9143\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.3169 - accuracy: 0.9104 - val_loss: 0.2899 - val_accuracy: 0.9183\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2999 - accuracy: 0.9144 - val_loss: 0.2768 - val_accuracy: 0.9218\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2858 - accuracy: 0.9183 - val_loss: 0.2651 - val_accuracy: 0.9254\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2746 - accuracy: 0.9214 - val_loss: 0.2558 - val_accuracy: 0.9276\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.2643 - accuracy: 0.9237 - val_loss: 0.2490 - val_accuracy: 0.9294\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2550 - accuracy: 0.9272 - val_loss: 0.2406 - val_accuracy: 0.9323\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.2463 - accuracy: 0.9296 - val_loss: 0.2341 - val_accuracy: 0.9337\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2385 - accuracy: 0.9318 - val_loss: 0.2304 - val_accuracy: 0.9339\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2316 - accuracy: 0.9339 - val_loss: 0.2228 - val_accuracy: 0.9364\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2247 - accuracy: 0.9363 - val_loss: 0.2163 - val_accuracy: 0.9389\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.2185 - accuracy: 0.9373 - val_loss: 0.2111 - val_accuracy: 0.9411\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2126 - accuracy: 0.9395 - val_loss: 0.2068 - val_accuracy: 0.9417\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2070 - accuracy: 0.9414 - val_loss: 0.2028 - val_accuracy: 0.9429\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2016 - accuracy: 0.9425 - val_loss: 0.1994 - val_accuracy: 0.9433\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.1967 - accuracy: 0.9441 - val_loss: 0.1948 - val_accuracy: 0.9455\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.1918 - accuracy: 0.9453 - val_loss: 0.1913 - val_accuracy: 0.9460\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1870 - accuracy: 0.9469 - val_loss: 0.1889 - val_accuracy: 0.9462\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.1829 - accuracy: 0.9480 - val_loss: 0.1850 - val_accuracy: 0.9480\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.1788 - accuracy: 0.9491 - val_loss: 0.1816 - val_accuracy: 0.9472\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1745 - accuracy: 0.9505 - val_loss: 0.1787 - val_accuracy: 0.9481\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.1706 - accuracy: 0.9519 - val_loss: 0.1751 - val_accuracy: 0.9503\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1668 - accuracy: 0.9524 - val_loss: 0.1728 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1630 - accuracy: 0.9537 - val_loss: 0.1698 - val_accuracy: 0.9519\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1597 - accuracy: 0.9543 - val_loss: 0.1662 - val_accuracy: 0.9523\n",
      "Epoch 30/30\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1562 - accuracy: 0.9555 - val_loss: 0.1640 - val_accuracy: 0.9523\n",
      "10000/10000 [==============================] - 1s 75us/step\n",
      "Test score: 0.1603286850646138\n",
      "Test accuracy: 0.953499972820282\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(1671) # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 30\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10321665166078624861\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4963368960\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 74006820213408317\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d020614f9a2dc57296da84a5f935b826668275142c238b2790968ef78e3430c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
